# Pipeline de Analytics em Tempo Real do Spotify

![Snowflake](https://img.shields.io/badge/Snowflake-29B5E8?logo=snowflake&logoColor=white)
![DBT](https://img.shields.io/badge/dbt-FF694B?logo=dbt&logoColor=white)
![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-017CEE?logo=apacheairflow&logoColor=white)
![Apache Kafka](https://img.shields.io/badge/Apache%20Kafka-231F20?logo=apachekafka&logoColor=white)
![Python](https://img.shields.io/badge/Python-3776AB?logo=python&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-2496ED?logo=docker&logoColor=white)
![Power BI](https://img.shields.io/badge/Power%20BI-F2C811?logo=powerbi&logoColor=black)
![Modern Data Stack](https://img.shields.io/badge/Modern%20Data%20Stack-00C7B7?logo=databricks&logoColor=white)
---

Pipeline de dados completo end-to-end para analytics de streaming do Spotify usando Modern Data Stack
Funcionalidades â€¢ Arquitetura â€¢ InÃ­cio RÃ¡pido â€¢ DocumentaÃ§Ã£o â€¢ Contribuindo
ğŸ¯ VisÃ£o Geral
Este projeto implementa um pipeline de dados em tempo real de nÃ­vel produÃ§Ã£o para analytics de streaming de mÃºsica do Spotify, demonstrando as melhores prÃ¡ticas de engenharia de dados moderna. O pipeline simula milhÃµes de eventos de streaming, processa-os em tempo real e entrega insights acionÃ¡veis atravÃ©s de dashboards interativos.
O Que Torna Este Projeto Especial?

ğŸš€ Totalmente Automatizado: Uma vez iniciado, o pipeline roda de forma autÃ´noma ponta a ponta
âš¡ Processamento em Tempo Real: LatÃªncia inferior a um segundo desde geraÃ§Ã£o atÃ© visualizaÃ§Ã£o
ğŸ—ï¸ Pronto para ProduÃ§Ã£o: Implementa padrÃµes e prÃ¡ticas da indÃºstria
ğŸ“¦ 100% Containerizado: Deploy com um Ãºnico comando usando Docker Compose
ğŸ”„ Arquitetura Medallion: Camadas de dados Bronze â†’ Silver â†’ Gold
âœ… Qualidade em Primeiro Lugar: Testes e validaÃ§Ãµes integrados em cada etapa

Valor de NegÃ³cio
Este pipeline responde questÃµes crÃ­ticas de negÃ³cio:

ğŸ“Š Quais mÃºsicas estÃ£o em alta agora?
ğŸŒ Quais regiÃµes tÃªm maior engajamento?
ğŸ“± Como os usuÃ¡rios consomem conteÃºdo em diferentes dispositivos?
â° Quais sÃ£o os horÃ¡rios de pico de escuta?
ğŸ­ Quais gÃªneros estÃ£o ganhando popularidade?

---
âœ¨ Funcionalidades
Capacidades Principais

Streaming em Tempo Real: Apache Kafka processa milhÃµes de eventos por segundo
Armazenamento EscalÃ¡vel: MinIO fornece armazenamento de objetos compatÃ­vel com S3
Data Warehouse em Nuvem: Snowflake permite analytics em escala de petabytes
TransformaÃ§Ã£o de Dados: dbt garante modelos de dados limpos, testados e documentados
OrquestraÃ§Ã£o de Workflows: Airflow gerencia dependÃªncias complexas e agendamentos
Dashboards Interativos: Power BI entrega insights aos stakeholders

Melhores PrÃ¡ticas de Engenharia de Dados

âœ… Arquitetura Medallion (Bronze/Silver/Gold)
âœ… Processamento Incremental (apenas dados novos)
âœ… Testes de Qualidade de Dados (dbt tests)
âœ… ValidaÃ§Ã£o de Schema (verificaÃ§Ãµes automatizadas)
âœ… Pipelines Idempotentes (execuÃ§Ãµes seguras)
âœ… Rastreamento de Linhagem (proveniÃªncia dos dados)
âœ… DocumentaÃ§Ã£o como CÃ³digo (dbt docs)
---

ğŸ—ï¸ Arquitetura
Diagrama de Arquitetura de Alto NÃ­vel
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         GERAÃ‡ÃƒO DE DADOS                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Simulador Python (Faker)                                   â”‚     â”‚
â”‚  â”‚  â€¢ Gera eventos realistas de streaming                      â”‚     â”‚
â”‚  â”‚  â€¢ ~1000 eventos/segundo                                    â”‚     â”‚
â”‚  â”‚  â€¢ SimulaÃ§Ã£o multi-regiÃ£o e multi-dispositivo               â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      STREAMING EM TEMPO REAL                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Apache Kafka                                               â”‚     â”‚
â”‚  â”‚  â€¢ TÃ³pico: spotify_plays                                    â”‚     â”‚
â”‚  â”‚  â€¢ PartiÃ§Ãµes: 3                                             â”‚     â”‚
â”‚  â”‚  â€¢ RetenÃ§Ã£o: 7 dias                                         â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       DATA LAKE (BRUTO)                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  MinIO (CompatÃ­vel com S3)                                  â”‚     â”‚
â”‚  â”‚  â€¢ Bucket: spotify-raw-data                                 â”‚     â”‚
â”‚  â”‚  â€¢ Formato: JSON (particionado por data)                    â”‚     â”‚
â”‚  â”‚  â€¢ Caminho: /ano/mes/dia/hora/                             â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CAMADA DE ORQUESTRAÃ‡ÃƒO                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Apache Airflow                                             â”‚     â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚     â”‚
â”‚  â”‚  â”‚ DAG 1: spotify_ingestion_pipeline                    â”‚ â”‚     â”‚
â”‚  â”‚  â”‚ â€¢ Extrai do MinIO                                    â”‚ â”‚     â”‚
â”‚  â”‚  â”‚ â€¢ Carrega no Snowflake Bronze                        â”‚ â”‚     â”‚
â”‚  â”‚  â”‚ â€¢ Agendamento: A cada 5 minutos                      â”‚ â”‚     â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚     â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚     â”‚
â”‚  â”‚  â”‚ DAG 2: spotify_transformation_pipeline               â”‚ â”‚     â”‚
â”‚  â”‚  â”‚ â€¢ Dispara transformaÃ§Ãµes dbt                         â”‚ â”‚     â”‚
â”‚  â”‚  â”‚ â€¢ Bronze â†’ Silver â†’ Gold                             â”‚ â”‚     â”‚
â”‚  â”‚  â”‚ â€¢ Agendamento: A cada 10 minutos                     â”‚ â”‚     â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   DATA WAREHOUSE (SNOWFLAKE)                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  ğŸ¥‰ CAMADA BRONZE (Bruto)                                   â”‚     â”‚
â”‚  â”‚  â€¢ RAW_PLAYS (coluna VARIANT com JSON completo)            â”‚     â”‚
â”‚  â”‚  â€¢ Sem transformaÃ§Ãµes aplicadas                            â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                            â”‚                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  ğŸ¥ˆ CAMADA SILVER (Limpo e Padronizado)                     â”‚     â”‚
â”‚  â”‚  â€¢ STG_PLAYS: Dados de reproduÃ§Ãµes limpos                   â”‚     â”‚
â”‚  â”‚  â€¢ STG_TRACKS: MÃºsicas deduplicadas                         â”‚     â”‚
â”‚  â”‚  â€¢ STG_USERS: UsuÃ¡rios Ãºnicos                               â”‚     â”‚
â”‚  â”‚  â€¢ Tipos de dados validados, nulos tratados                 â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                            â”‚                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  ğŸ¥‡ CAMADA GOLD (Marts de NegÃ³cio)                          â”‚     â”‚
â”‚  â”‚  â€¢ FCT_PLAYS: Tabela fato (eventos de streaming)            â”‚     â”‚
â”‚  â”‚  â€¢ DIM_TRACKS: DimensÃ£o de mÃºsicas                          â”‚     â”‚
â”‚  â”‚  â€¢ DIM_ARTISTS: DimensÃ£o de artistas                        â”‚     â”‚
â”‚  â”‚  â€¢ DIM_REGIONS: DimensÃ£o geogrÃ¡fica                         â”‚     â”‚
â”‚  â”‚  â€¢ DIM_TIME: DimensÃ£o temporal                              â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TRANSFORMAÃ‡ÃƒO DE DADOS (DBT)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  â€¢ TransformaÃ§Ãµes baseadas em SQL                           â”‚     â”‚
â”‚  â”‚  â€¢ Testes automatizados (unicidade, not_null, relacionamen.)â”‚     â”‚
â”‚  â”‚  â€¢ GeraÃ§Ã£o de documentaÃ§Ã£o                                  â”‚     â”‚
â”‚  â”‚  â€¢ Rastreamento de linhagem                                 â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BUSINESS INTELLIGENCE                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Dashboard Power BI                                         â”‚     â”‚
â”‚  â”‚  ğŸ“Š Total de ReproduÃ§Ãµes: 15,2M                             â”‚     â”‚
â”‚  â”‚  ğŸ‘¥ Ouvintes Ãšnicos: 892K                                   â”‚     â”‚
â”‚  â”‚  ğŸŒ RegiÃ£o Top: CalifÃ³rnia (2,3M reproduÃ§Ãµes)              â”‚     â”‚
â”‚  â”‚  ğŸ“± DivisÃ£o Dispositivos: 60% Mobile, 25% Desktop, 15% Web â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Fluxo de Dados Explicado

GeraÃ§Ã£o: Simulador Python cria eventos realistas de streaming usando biblioteca Faker
Streaming: Producer Kafka publica eventos no tÃ³pico spotify_plays
Consumo: Consumer Kafka lÃª mensagens e escreve arquivos JSON no MinIO
IngestÃ£o: DAG do Airflow copia arquivos do MinIO para camada Bronze do Snowflake
TransformaÃ§Ã£o: Modelos dbt limpam, padronizam e agregam dados (Silver â†’ Gold)
VisualizaÃ§Ã£o: Power BI conecta Ã  camada Gold para dashboards em tempo real
---
ğŸ› ï¸ Stack TecnolÃ³gica
Infraestrutura & OrquestraÃ§Ã£o

<img width="572" height="143" alt="image" src="https://github.com/user-attachments/assets/1eadc016-9711-44f4-8e35-7cf39e167e41" />

---

Streaming & Armazenamento
<img width="559" height="217" alt="image" src="https://github.com/user-attachments/assets/2c9b8c12-b0fb-45e2-b76e-3d9426ce8453" />

---
Processamento de Dados
<img width="560" height="164" alt="image" src="https://github.com/user-attachments/assets/955cac64-f5ce-485c-9420-830d1cd23484" />

---
VisualizaÃ§Ã£o
<img width="560" height="74" alt="image" src="https://github.com/user-attachments/assets/f9512355-7192-486f-8a17-6352feb2bfec" />

---
Bibliotecas Python
faker==19.12.0
kafka-python==2.0.2
minio==7.1.17
pandas==2.1.3
snowflake-connector-python==3.3.1
apache-airflow==2.7.3
dbt-snowflake==1.6.2
---

ğŸ“ Estrutura do Projeto
spotify-mds-pipeline/
â”‚
â”œâ”€â”€ ğŸ“ docker/                          # ConfiguraÃ§Ãµes Docker e Airflow
â”‚   â”œâ”€â”€ .env                           # VariÃ¡veis de ambiente para Airflow
â”‚   â”œâ”€â”€ docker-compose.yml             # DefiniÃ§Ã£o de serviÃ§os Airflow
â”‚   â”œâ”€â”€ Dockerfile                     # Imagem customizada do Airflow
â”‚   â”œâ”€â”€ requirements.txt               # DependÃªncias Python do Airflow
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ dags/                       # DAGs do Airflow
â”‚       â”œâ”€â”€ spotify_ingestion.py       # MinIO â†’ Snowflake Bronze
â”‚       â”œâ”€â”€ spotify_transformation.py  # Dispara execuÃ§Ãµes dbt
â”‚       â”œâ”€â”€ utils/                     # UtilitÃ¡rios compartilhados
â”‚       â”‚   â”œâ”€â”€ snowflake_conn.py     # Helper de conexÃ£o Snowflake
â”‚       â”‚   â””â”€â”€ slack_alerts.py       # Sistema de notificaÃ§Ãµes
â”‚       â””â”€â”€ .env                       # VariÃ¡veis especÃ­ficas das DAGs
â”‚
â”œâ”€â”€ ğŸ“ simulator/                       # ServiÃ§o de geraÃ§Ã£o de dados
â”‚   â”œâ”€â”€ producer.py                    # Producer Kafka (gera eventos)
â”‚   â”œâ”€â”€ schemas.py                     # Schemas e validaÃ§Ã£o de dados
â”‚   â”œâ”€â”€ config.py                      # Gerenciamento de configuraÃ§Ã£o
â”‚   â”œâ”€â”€ Dockerfile                     # Container do simulador
â”‚   â”œâ”€â”€ requirements.txt               # DependÃªncias Python
â”‚   â””â”€â”€ .env                           # VariÃ¡veis de ambiente do producer
â”‚
â”œâ”€â”€ ğŸ“ consumer/                        # ServiÃ§o consumer Kafka
â”‚   â”œâ”€â”€ kafka_to_minio.py             # Consome do Kafka â†’ MinIO
â”‚   â”œâ”€â”€ config.py                      # ConfiguraÃ§Ã£o do consumer
â”‚   â”œâ”€â”€ Dockerfile                     # Container do consumer
â”‚   â”œâ”€â”€ requirements.txt               # DependÃªncias Python
â”‚   â””â”€â”€ .env                           # VariÃ¡veis de ambiente do consumer
â”‚
â”œâ”€â”€ ğŸ“ spotify_dbt/                     # Projeto dbt
â”‚   â”œâ”€â”€ dbt_project.yml                # ConfiguraÃ§Ã£o do projeto dbt
â”‚   â”œâ”€â”€ profiles.yml                   # Perfis de conexÃ£o Snowflake
â”‚   â”œâ”€â”€ packages.yml                   # Pacotes dbt (dbt_utils, etc.)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ models/                     # Modelos dbt
â”‚   â”‚   â”œâ”€â”€ sources.yml                # DefiniÃ§Ãµes de fontes (camada Bronze)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“ staging/                # Camada Silver (dados limpos)
â”‚   â”‚   â”‚   â”œâ”€â”€ stg_plays.sql         # Staging: eventos de reproduÃ§Ã£o
â”‚   â”‚   â”‚   â”œâ”€â”€ stg_tracks.sql        # Staging: metadados de mÃºsicas
â”‚   â”‚   â”‚   â”œâ”€â”€ stg_users.sql         # Staging: usuÃ¡rios
â”‚   â”‚   â”‚   â”œâ”€â”€ stg_regions.sql       # Staging: dados geogrÃ¡ficos
â”‚   â”‚   â”‚   â””â”€â”€ schema.yml            # Testes e documentaÃ§Ã£o
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“ intermediate/           # TransformaÃ§Ãµes intermediÃ¡rias
â”‚   â”‚   â”‚   â”œâ”€â”€ int_plays_enriched.sql # ReproduÃ§Ãµes com info de mÃºsicas
â”‚   â”‚   â”‚   â””â”€â”€ int_user_metrics.sql   # AgregaÃ§Ãµes por usuÃ¡rio
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ğŸ“ marts/                  # Camada Gold (marts de negÃ³cio)
â”‚   â”‚       â”œâ”€â”€ ğŸ“ core/
â”‚   â”‚       â”‚   â”œâ”€â”€ fct_plays.sql     # Fato: eventos de streaming
â”‚   â”‚       â”‚   â”œâ”€â”€ dim_tracks.sql    # DimensÃ£o: mÃºsicas
â”‚   â”‚       â”‚   â”œâ”€â”€ dim_artists.sql   # DimensÃ£o: artistas
â”‚   â”‚       â”‚   â”œâ”€â”€ dim_regions.sql   # DimensÃ£o: regiÃµes
â”‚   â”‚       â”‚   â”œâ”€â”€ dim_devices.sql   # DimensÃ£o: dispositivos
â”‚   â”‚       â”‚   â””â”€â”€ dim_time.sql      # DimensÃ£o: tempo
â”‚   â”‚       â”‚
â”‚   â”‚       â””â”€â”€ ğŸ“ analytics/
â”‚   â”‚           â”œâ”€â”€ top_tracks_daily.sql      # Top mÃºsicas diÃ¡rias
â”‚   â”‚           â”œâ”€â”€ regional_trends.sql       # Analytics regionais
â”‚   â”‚           â””â”€â”€ user_engagement.sql       # MÃ©tricas de comportamento
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ macros/                     # Macros customizados dbt
â”‚   â”‚   â”œâ”€â”€ generate_schema_name.sql   # LÃ³gica de nomeaÃ§Ã£o de schemas
â”‚   â”‚   â””â”€â”€ custom_tests.sql           # Testes customizados de qualidade
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ tests/                      # Testes customizados de dados
â”‚   â”‚   â””â”€â”€ assert_positive_plays.sql  # ValidaÃ§Ãµes de regras de negÃ³cio
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ snapshots/                  # DimensÃµes de mudanÃ§a lenta
â”‚       â””â”€â”€ scd_tracks.sql             # Snapshots de histÃ³rico de mÃºsicas
â”‚
â”œâ”€â”€ ğŸ“ dashboards/                      # RelatÃ³rios Power BI
â”‚   â”œâ”€â”€ spotify_analytics.pbix         # Arquivo principal do dashboard
â”‚   â”œâ”€â”€ queries/                       # Queries DAX customizadas
â”‚   â””â”€â”€ screenshots/                   # Imagens de preview do dashboard
â”‚
â”œâ”€â”€ ğŸ“ infrastructure/                  # Infraestrutura como CÃ³digo (opcional)
â”‚   â”œâ”€â”€ terraform/                     # ConfiguraÃ§Ãµes Terraform
â”‚   â”‚   â”œâ”€â”€ main.tf                   # Infraestrutura principal
â”‚   â”‚   â”œâ”€â”€ snowflake.tf              # Recursos Snowflake
â”‚   â”‚   â””â”€â”€ variables.tf              # VariÃ¡veis
â”‚   â””â”€â”€ scripts/                       # Scripts de setup
â”‚       â”œâ”€â”€ setup_snowflake.sql       # InicializaÃ§Ã£o Snowflake
â”‚       â””â”€â”€ create_buckets.sh         # CriaÃ§Ã£o de buckets MinIO
â”‚
â”œâ”€â”€ ğŸ“ tests/                           # Testes da aplicaÃ§Ã£o
â”‚   â”œâ”€â”€ unit/                          # Testes unitÃ¡rios
â”‚   â”œâ”€â”€ integration/                   # Testes de integraÃ§Ã£o
â”‚   â””â”€â”€ fixtures/                      # Dados de teste
â”‚
â”œâ”€â”€ ğŸ“ docs/                            # DocumentaÃ§Ã£o
â”‚   â”œâ”€â”€ ARCHITECTURE.md                # DocumentaÃ§Ã£o detalhada da arquitetura
â”‚   â”œâ”€â”€ DATA_MODEL.md                  # DocumentaÃ§Ã£o do modelo de dados
â”‚   â”œâ”€â”€ SETUP.md                       # Guia de setup
â”‚   â”œâ”€â”€ TROUBLESHOOTING.md             # Problemas comuns
â”‚   â””â”€â”€ images/                        # Diagramas de arquitetura
â”‚
â”œâ”€â”€ .env.example                        # Exemplo de variÃ¡veis de ambiente
â”œâ”€â”€ .gitignore                          # PadrÃµes de ignore do Git
â”œâ”€â”€ docker-compose.yml                  # Arquivo principal de orquestraÃ§Ã£o
â”œâ”€â”€ Makefile                            # Comandos de conveniÃªncia
â”œâ”€â”€ requirements.txt                    # DependÃªncias Python raiz
â”œâ”€â”€ README.md                           # Este arquivo
â””â”€â”€ LICENSE                             # LicenÃ§a do projeto

---
ğŸ”§ PrÃ©-requisitos
Software NecessÃ¡rio

Docker Desktop (4.20+) - Download
Docker Compose (2.20+) - IncluÃ­do no Docker Desktop
Git - Download
Conta Snowflake - Cadastre-se para teste grÃ¡tis
Power BI Desktop (opcional) - Download

---

Requisitos de Sistema
<img width="562" height="164" alt="image" src="https://github.com/user-attachments/assets/e97ff0d5-e1df-4f94-96f0-b04a9d41d6ff" />

---
Requisitos de Rede

ConexÃ£o com internet para imagens Docker e Snowflake
Portas disponÃ­veis: 8080 (Airflow), 9092 (Kafka), 9000-9001 (MinIO), 2181 (Zookeeper)

---
ğŸš€ InstalaÃ§Ã£o
1. Clone o RepositÃ³rio
   git clone https://github.com/maiconaalmeida/spotify-mds-pipeline.git
cd spotify-mds-pipeline
---

2. Configure as VariÃ¡veis de Ambiente
# Copie o arquivo de exemplo
cp .env.example .env

# Edite o arquivo .env com suas credenciais
nano .env  # ou vim, code, etc.
---

VariÃ¡veis ObrigatÃ³rias:
# ConfiguraÃ§Ã£o Snowflake
SNOWFLAKE_ACCOUNT=seu_identificador_conta
SNOWFLAKE_USER=seu_usuario
SNOWFLAKE_PASSWORD=sua_senha
SNOWFLAKE_WAREHOUSE=COMPUTE_WH
SNOWFLAKE_DATABASE=SPOTIFY_DB
SNOWFLAKE_SCHEMA=BRONZE
SNOWFLAKE_ROLE=ACCOUNTADMIN

# ConfiguraÃ§Ã£o MinIO
MINIO_ROOT_USER=admin
MINIO_ROOT_PASSWORD=senha_admin_minio
MINIO_BUCKET_NAME=spotify-raw-data

# ConfiguraÃ§Ã£o Kafka
KAFKA_BROKER=kafka:9092
KAFKA_TOPIC=spotify_plays

# ConfiguraÃ§Ã£o Airflow
AIRFLOW_UID=50000
AIRFLOW__CORE__FERNET_KEY=sua_chave_fernet_aqui

---
3. Inicialize o Snowflake
Execute o script de setup para criar bancos de dados, schemas e tabelas:
# Conecte ao Snowflake e execute
./infrastructure/scripts/setup_snowflake.sql

Ou execute manualmente:
-- Criar banco de dados e schemas
CREATE DATABASE IF NOT EXISTS SPOTIFY_DB;

CREATE SCHEMA IF NOT EXISTS SPOTIFY_DB.BRONZE;
CREATE SCHEMA IF NOT EXISTS SPOTIFY_DB.SILVER;
CREATE SCHEMA IF NOT EXISTS SPOTIFY_DB.GOLD;

-- Criar tabela da camada Bronze
CREATE TABLE IF NOT EXISTS SPOTIFY_DB.BRONZE.RAW_PLAYS (
    raw_data VARIANT,
    load_timestamp TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),
    source_file STRING,
    _metadata VARIANT
);

-- Criar formato de arquivo para JSON
CREATE FILE FORMAT IF NOT EXISTS SPOTIFY_DB.BRONZE.JSON_FORMAT
    TYPE = 'JSON'
    COMPRESSION = 'AUTO'
    STRIP_OUTER_ARRAY = TRUE;

-- Criar warehouse (se nÃ£o existir)
CREATE WAREHOUSE IF NOT EXISTS COMPUTE_WH
    WAREHOUSE_SIZE = 'XSMALL'
    AUTO_SUSPEND = 60
    AUTO_RESUME = TRUE;
---
4. Construa e Inicie os ServiÃ§os
   # Construir todas as imagens Docker
docker-compose build

# Iniciar todos os serviÃ§os em modo detached
docker-compose up -d

# Verificar status dos serviÃ§os
docker-compose ps

SaÃ­da Esperada:
NOME                    STATUS              PORTAS
kafka                   running             0.0.0.0:9092->9092/tcp
zookeeper               running             0.0.0.0:2181->2181/tcp
minio                   running             0.0.0.0:9000-9001->9000-9001/tcp
airflow-webserver       running             0.0.0.0:8080->8080/tcp
airflow-scheduler       running
producer                running
consumer                running

---
5. Acesse os ServiÃ§os
   <img width="555" height="178" alt="image" src="https://github.com/user-attachments/assets/f42ef2f2-79c0-4b01-8dec-5ac43cf07ff5" />

---
6. Verifique a InstalaÃ§Ã£o
# Verificar logs do Airflow
docker-compose logs -f airflow-webserver

# Verificar tÃ³picos Kafka
docker-compose exec kafka kafka-topics --list --bootstrap-server localhost:9092

# Verificar buckets MinIO
docker-compose exec minio mc ls minio/

# Testar conexÃ£o Snowflake
docker-compose exec airflow-webserver airflow connections test snowflake_default

---
âš™ï¸ ConfiguraÃ§Ã£o
ConexÃµes do Airflow
Configure a conexÃ£o Snowflake na UI do Airflow:

Navegue atÃ© Admin â†’ Connections
Clique em + para adicionar nova conexÃ£o
Preencha os detalhes:

Connection Id: snowflake_default
Connection Type: Snowflake
Account: seu_identificador_conta
Warehouse: COMPUTE_WH
Database: SPOTIFY_DB
Role: ACCOUNTADMIN
Login: seu_usuario
Password: sua_senha

---
Perfil dbt
Edite spotify_dbt/profiles.yml:
spotify_dbt:
  outputs:
    dev:
      type: snowflake
      account: "{{ env_var('SNOWFLAKE_ACCOUNT') }}"
      user: "{{ env_var('SNOWFLAKE_USER') }}"
      password: "{{ env_var('SNOWFLAKE_PASSWORD') }}"
      role: ACCOUNTADMIN
      database: SPOTIFY_DB
      warehouse: COMPUTE_WH
      schema: SILVER
      threads: 4
      client_session_keep_alive: False
    
    prod:
      type: snowflake
      account: "{{ env_var('SNOWFLAKE_ACCOUNT') }}"
      user: "{{ env_var('SNOWFLAKE_USER') }}"
      password: "{{ env_var('SNOWFLAKE_PASSWORD') }}"
      role: ACCOUNTADMIN
      database: SPOTIFY_DB
      warehouse: COMPUTE_WH
      schema: GOLD
      threads: 8
      client_session_keep_alive: False
  
  target: dev

  ---
  ConfiguraÃ§Ã£o de TÃ³picos Kafka
Ajuste partiÃ§Ãµes e replicaÃ§Ã£o:
docker-compose exec kafka kafka-topics \
  --create \
  --topic spotify_plays \
  --bootstrap-server localhost:9092 \
  --partitions 3 \
  --replication-factor 1 \
  --config retention.ms=604800000  # 7 dias

  ---
  ğŸ® Como Usar
Iniciando o Pipeline
# Iniciar todos os serviÃ§os
make start

# Ou usando docker-compose
docker-compose up -d

---
Monitoramento
Ver Logs:
# Todos os serviÃ§os
docker-compose logs -f

# ServiÃ§o especÃ­fico
docker-compose logs -f producer
docker-compose logs -f consumer
docker-compose logs -f airflow-scheduler

---
# Todos os serviÃ§os
docker-compose logs -f

# ServiÃ§o especÃ­fico
docker-compose logs -f producer
docker-compose logs -f consumer
docker-compose logs -f airflow-scheduler

---
UI do Airflow:

Abra http://localhost:8080
Habilite as DAGs: spotify_ingestion_pipeline e spotify_transformation_pipeline
Monitore a execuÃ§Ã£o das tasks na visualizaÃ§Ã£o Graph ou Tree

Console MinIO:

Abra http://localhost:9001
Navegue no bucket spotify-raw-data
Verifique se arquivos JSON estÃ£o sendo criados

Executando dbt Manualmente
---

# Entrar no container Airflow
docker-compose exec airflow-webserver bash

# Navegar para o projeto dbt
cd /opt/dbt/spotify_dbt

# Executar todos os modelos
dbt run

# Executar modelos especÃ­ficos
dbt run --models

