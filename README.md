
# üéµ Pipeline de Analytics em Tempo Real do Spotify
![Snowflake](https://img.shields.io/badge/Snowflake-29B5E8?logo=snowflake&logoColor=white)
![DBT](https://img.shields.io/badge/dbt-FF694B?logo=dbt&logoColor=white)
![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-017CEE?logo=apacheairflow&logoColor=white)
![Apache Kafka](https://img.shields.io/badge/Apache%20Kafka-231F20?logo=apachekafka&logoColor=white)
![Python](https://img.shields.io/badge/Python-3776AB?logo=python&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-2496ED?logo=docker&logoColor=white)
![Power BI](https://img.shields.io/badge/Power%20BI-F2C811?logo=powerbi&logoColor=black)
![Modern Data Stack](https://img.shields.io/badge/Modern%20Data%20Stack-00C7B7?logo=databricks&logoColor=white)
---

<div align="center">

![Status Pipeline](https://img.shields.io/badge/pipeline-ativo-success)
![Docker](https://img.shields.io/badge/docker-pronto-blue)
![Licen√ßa](https://img.shields.io/badge/licen%C3%A7a-MIT-green)
![Python](https://img.shields.io/badge/python-3.9+-blue)

**Pipeline de dados completo end-to-end para analytics de streaming do Spotify usando Modern Data Stack**

[Funcionalidades](#-funcionalidades) ‚Ä¢ [Arquitetura](#-arquitetura) ‚Ä¢ [In√≠cio R√°pido](#-in√≠cio-r√°pido) ‚Ä¢ [Documenta√ß√£o](#-documenta√ß√£o) ‚Ä¢ [Contribuindo](#-contribuindo)

</div>

---

## üìã √çndice

- [Vis√£o Geral](#-vis√£o-geral)
- [Funcionalidades](#-funcionalidades)
- [Arquitetura](#-arquitetura)
- [Stack Tecnol√≥gica](#-stack-tecnol√≥gica)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [Pr√©-requisitos](#-pr√©-requisitos)
- [Instala√ß√£o](#-instala√ß√£o)
- [Configura√ß√£o](#-configura√ß√£o)
- [Como Usar](#-como-usar)
- [Modelo de Dados](#-modelo-de-dados)
- [Monitoramento](#-monitoramento)
- [Testes](#-testes)
- [Solu√ß√£o de Problemas](#-solu√ß√£o-de-problemas)
- [Roadmap](#-roadmap)
- [Contribuindo](#-contribuindo)
- [Licen√ßa](#-licen√ßa)

---

## üéØ Vis√£o Geral

Este projeto implementa um **pipeline de dados em tempo real de n√≠vel produ√ß√£o** para analytics de streaming de m√∫sica do Spotify, demonstrando as melhores pr√°ticas de engenharia de dados moderna. O pipeline simula milh√µes de eventos de streaming, processa-os em tempo real e entrega insights acion√°veis atrav√©s de dashboards interativos.

### O Que Torna Este Projeto Especial?

- üöÄ **Totalmente Automatizado**: Uma vez iniciado, o pipeline roda de forma aut√¥noma ponta a ponta
- ‚ö° **Processamento em Tempo Real**: Lat√™ncia inferior a um segundo desde gera√ß√£o at√© visualiza√ß√£o
- üèóÔ∏è **Pronto para Produ√ß√£o**: Implementa padr√µes e pr√°ticas da ind√∫stria
- üì¶ **100% Containerizado**: Deploy com um √∫nico comando usando Docker Compose
- üîÑ **Arquitetura Medallion**: Camadas de dados Bronze ‚Üí Silver ‚Üí Gold
- ‚úÖ **Qualidade em Primeiro Lugar**: Testes e valida√ß√µes integrados em cada etapa

### Valor de Neg√≥cio

Este pipeline responde quest√µes cr√≠ticas de neg√≥cio:
- üìä Quais m√∫sicas est√£o em alta agora?
- üåç Quais regi√µes t√™m maior engajamento?
- üì± Como os usu√°rios consomem conte√∫do em diferentes dispositivos?
- ‚è∞ Quais s√£o os hor√°rios de pico de escuta?
- üé≠ Quais g√™neros est√£o ganhando popularidade?

---

## ‚ú® Funcionalidades

### Capacidades Principais

- **Streaming em Tempo Real**: Apache Kafka processa milh√µes de eventos por segundo
- **Armazenamento Escal√°vel**: MinIO fornece armazenamento de objetos compat√≠vel com S3
- **Data Warehouse em Nuvem**: Snowflake permite analytics em escala de petabytes
- **Transforma√ß√£o de Dados**: dbt garante modelos de dados limpos, testados e documentados
- **Orquestra√ß√£o de Workflows**: Airflow gerencia depend√™ncias complexas e agendamentos
- **Dashboards Interativos**: Power BI entrega insights aos stakeholders

### Melhores Pr√°ticas de Engenharia de Dados

- ‚úÖ **Arquitetura Medallion** (Bronze/Silver/Gold)
- ‚úÖ **Processamento Incremental** (apenas dados novos)
- ‚úÖ **Testes de Qualidade de Dados** (dbt tests)
- ‚úÖ **Valida√ß√£o de Schema** (verifica√ß√µes automatizadas)
- ‚úÖ **Pipelines Idempotentes** (execu√ß√µes seguras)
- ‚úÖ **Rastreamento de Linhagem** (proveni√™ncia dos dados)
- ‚úÖ **Documenta√ß√£o como C√≥digo** (dbt docs)

---

## üèóÔ∏è Arquitetura

### Diagrama de Arquitetura de Alto N√≠vel

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         GERA√á√ÉO DE DADOS                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ  Simulador Python (Faker)                                   ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Gera eventos realistas de streaming                      ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ ~1000 eventos/segundo                                    ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Simula√ß√£o multi-regi√£o e multi-dispositivo               ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      STREAMING EM TEMPO REAL                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ  Apache Kafka                                               ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ T√≥pico: spotify_plays                                    ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Parti√ß√µes: 3                                             ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Reten√ß√£o: 7 dias                                         ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                       DATA LAKE (BRUTO)                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ  MinIO (Compat√≠vel com S3)                                  ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Bucket: spotify-raw-data                                 ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Formato: JSON (particionado por data)                    ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Caminho: /ano/mes/dia/hora/                             ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    CAMADA DE ORQUESTRA√á√ÉO                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ  Apache Airflow                                             ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ DAG 1: spotify_ingestion_pipeline                    ‚îÇ ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ ‚Ä¢ Extrai do MinIO                                    ‚îÇ ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ ‚Ä¢ Carrega no Snowflake Bronze                        ‚îÇ ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ ‚Ä¢ Agendamento: A cada 5 minutos                      ‚îÇ ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ DAG 2: spotify_transformation_pipeline               ‚îÇ ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ ‚Ä¢ Dispara transforma√ß√µes dbt                         ‚îÇ ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ ‚Ä¢ Bronze ‚Üí Silver ‚Üí Gold                             ‚îÇ ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ ‚Ä¢ Agendamento: A cada 10 minutos                     ‚îÇ ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   DATA WAREHOUSE (SNOWFLAKE)                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ  ü•â CAMADA BRONZE (Bruto)                                   ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ RAW_PLAYS (coluna VARIANT com JSON completo)            ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Sem transforma√ß√µes aplicadas                            ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                            ‚îÇ                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  ü•à CAMADA SILVER (Limpo e Padronizado)                     ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ STG_PLAYS: Dados de reprodu√ß√µes limpos                   ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ STG_TRACKS: M√∫sicas deduplicadas                         ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ STG_USERS: Usu√°rios √∫nicos                               ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Tipos de dados validados, nulos tratados                 ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                            ‚îÇ                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  ü•á CAMADA GOLD (Marts de Neg√≥cio)                          ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ FCT_PLAYS: Tabela fato (eventos de streaming)            ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ DIM_TRACKS: Dimens√£o de m√∫sicas                          ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ DIM_ARTISTS: Dimens√£o de artistas                        ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ DIM_REGIONS: Dimens√£o geogr√°fica                         ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ DIM_TIME: Dimens√£o temporal                              ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    TRANSFORMA√á√ÉO DE DADOS (DBT)                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Transforma√ß√µes baseadas em SQL                           ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Testes automatizados (unicidade, not_null, relacionamen.)‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Gera√ß√£o de documenta√ß√£o                                  ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Rastreamento de linhagem                                 ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    BUSINESS INTELLIGENCE                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ  Dashboard Power BI                                         ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  üìä Total de Reprodu√ß√µes: 15,2M                             ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  üë• Ouvintes √önicos: 892K                                   ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  üåç Regi√£o Top: Calif√≥rnia (2,3M reprodu√ß√µes)              ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  üì± Divis√£o Dispositivos: 60% Mobile, 25% Desktop, 15% Web ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Fluxo de Dados Explicado

1. **Gera√ß√£o**: Simulador Python cria eventos realistas de streaming usando biblioteca Faker
2. **Streaming**: Producer Kafka publica eventos no t√≥pico `spotify_plays`
3. **Consumo**: Consumer Kafka l√™ mensagens e escreve arquivos JSON no MinIO
4. **Ingest√£o**: DAG do Airflow copia arquivos do MinIO para camada Bronze do Snowflake
5. **Transforma√ß√£o**: Modelos dbt limpam, padronizam e agregam dados (Silver ‚Üí Gold)
6. **Visualiza√ß√£o**: Power BI conecta √† camada Gold para dashboards em tempo real

---

## üõ†Ô∏è Stack Tecnol√≥gica

### Infraestrutura & Orquestra√ß√£o

| Tecnologia | Vers√£o | Prop√≥sito |
|-----------|---------|-----------|
| **Docker** | 24.0+ | Plataforma de containeriza√ß√£o |
| **Docker Compose** | 2.20+ | Orquestra√ß√£o multi-container |
| **Apache Airflow** | 2.7+ | Orquestra√ß√£o e agendamento de workflows |

### Streaming & Armazenamento

| Tecnologia | Vers√£o | Prop√≥sito |
|-----------|---------|-----------|
| **Apache Kafka** | 3.5+ | Plataforma de streaming distribu√≠do |
| **Zookeeper** | 3.8+ | Coordena√ß√£o de cluster Kafka |
| **MinIO** | RELEASE.2023+ | Armazenamento de objetos compat√≠vel com S3 |
| **Snowflake** | Enterprise | Data warehouse em nuvem |

### Processamento de Dados

| Tecnologia | Vers√£o | Prop√≥sito |
|-----------|---------|-----------|
| **dbt (data build tool)** | 1.6+ | Transforma√ß√µes de dados baseadas em SQL |
| **Python** | 3.9+ | Gera√ß√£o e processamento de dados |
| **Pandas** | 2.0+ | Manipula√ß√£o de dados |
| **Faker** | 19.0+ | Gera√ß√£o de dados realistas |

### Visualiza√ß√£o

| Tecnologia | Vers√£o | Prop√≥sito |
|-----------|---------|-----------|
| **Power BI** | Desktop/Service | Dashboards de business intelligence |

### Bibliotecas Python

```
faker==19.12.0
kafka-python==2.0.2
minio==7.1.17
pandas==2.1.3
snowflake-connector-python==3.3.1
apache-airflow==2.7.3
dbt-snowflake==1.6.2
```

---

## üìÅ Estrutura do Projeto

```
spotify-mds-pipeline/
‚îÇ
‚îú‚îÄ‚îÄ üìÅ docker/                          # Configura√ß√µes Docker e Airflow
‚îÇ   ‚îú‚îÄ‚îÄ .env                           # Vari√°veis de ambiente para Airflow
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml             # Defini√ß√£o de servi√ßos Airflow
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile                     # Imagem customizada do Airflow
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt               # Depend√™ncias Python do Airflow
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ dags/                       # DAGs do Airflow
‚îÇ       ‚îú‚îÄ‚îÄ spotify_ingestion.py       # MinIO ‚Üí Snowflake Bronze
‚îÇ       ‚îú‚îÄ‚îÄ spotify_transformation.py  # Dispara execu√ß√µes dbt
‚îÇ       ‚îú‚îÄ‚îÄ utils/                     # Utilit√°rios compartilhados
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ snowflake_conn.py     # Helper de conex√£o Snowflake
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ slack_alerts.py       # Sistema de notifica√ß√µes
‚îÇ       ‚îî‚îÄ‚îÄ .env                       # Vari√°veis espec√≠ficas das DAGs
‚îÇ
‚îú‚îÄ‚îÄ üìÅ simulator/                       # Servi√ßo de gera√ß√£o de dados
‚îÇ   ‚îú‚îÄ‚îÄ producer.py                    # Producer Kafka (gera eventos)
‚îÇ   ‚îú‚îÄ‚îÄ schemas.py                     # Schemas e valida√ß√£o de dados
‚îÇ   ‚îú‚îÄ‚îÄ config.py                      # Gerenciamento de configura√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile                     # Container do simulador
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt               # Depend√™ncias Python
‚îÇ   ‚îî‚îÄ‚îÄ .env                           # Vari√°veis de ambiente do producer
‚îÇ
‚îú‚îÄ‚îÄ üìÅ consumer/                        # Servi√ßo consumer Kafka
‚îÇ   ‚îú‚îÄ‚îÄ kafka_to_minio.py             # Consome do Kafka ‚Üí MinIO
‚îÇ   ‚îú‚îÄ‚îÄ config.py                      # Configura√ß√£o do consumer
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile                     # Container do consumer
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt               # Depend√™ncias Python
‚îÇ   ‚îî‚îÄ‚îÄ .env                           # Vari√°veis de ambiente do consumer
‚îÇ
‚îú‚îÄ‚îÄ üìÅ spotify_dbt/                     # Projeto dbt
‚îÇ   ‚îú‚îÄ‚îÄ dbt_project.yml                # Configura√ß√£o do projeto dbt
‚îÇ   ‚îú‚îÄ‚îÄ profiles.yml                   # Perfis de conex√£o Snowflake
‚îÇ   ‚îú‚îÄ‚îÄ packages.yml                   # Pacotes dbt (dbt_utils, etc.)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ models/                     # Modelos dbt
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sources.yml                # Defini√ß√µes de fontes (camada Bronze)
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ staging/                # Camada Silver (dados limpos)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stg_plays.sql         # Staging: eventos de reprodu√ß√£o
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stg_tracks.sql        # Staging: metadados de m√∫sicas
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stg_users.sql         # Staging: usu√°rios
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stg_regions.sql       # Staging: dados geogr√°ficos
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schema.yml            # Testes e documenta√ß√£o
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ intermediate/           # Transforma√ß√µes intermedi√°rias
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ int_plays_enriched.sql # Reprodu√ß√µes com info de m√∫sicas
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ int_user_metrics.sql   # Agrega√ß√µes por usu√°rio
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÅ marts/                  # Camada Gold (marts de neg√≥cio)
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ üìÅ core/
‚îÇ   ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ fct_plays.sql     # Fato: eventos de streaming
‚îÇ   ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ dim_tracks.sql    # Dimens√£o: m√∫sicas
‚îÇ   ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ dim_artists.sql   # Dimens√£o: artistas
‚îÇ   ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ dim_regions.sql   # Dimens√£o: regi√µes
‚îÇ   ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ dim_devices.sql   # Dimens√£o: dispositivos
‚îÇ   ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ dim_time.sql      # Dimens√£o: tempo
‚îÇ   ‚îÇ       ‚îÇ
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ üìÅ analytics/
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ top_tracks_daily.sql      # Top m√∫sicas di√°rias
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ regional_trends.sql       # Analytics regionais
‚îÇ   ‚îÇ           ‚îî‚îÄ‚îÄ user_engagement.sql       # M√©tricas de comportamento
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ macros/                     # Macros customizados dbt
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ generate_schema_name.sql   # L√≥gica de nomea√ß√£o de schemas
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ custom_tests.sql           # Testes customizados de qualidade
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ tests/                      # Testes customizados de dados
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ assert_positive_plays.sql  # Valida√ß√µes de regras de neg√≥cio
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ snapshots/                  # Dimens√µes de mudan√ßa lenta
‚îÇ       ‚îî‚îÄ‚îÄ scd_tracks.sql             # Snapshots de hist√≥rico de m√∫sicas
‚îÇ
‚îú‚îÄ‚îÄ üìÅ dashboards/                      # Relat√≥rios Power BI
‚îÇ   ‚îú‚îÄ‚îÄ spotify_analytics.pbix         # Arquivo principal do dashboard
‚îÇ   ‚îú‚îÄ‚îÄ queries/                       # Queries DAX customizadas
‚îÇ   ‚îî‚îÄ‚îÄ screenshots/                   # Imagens de preview do dashboard
‚îÇ
‚îú‚îÄ‚îÄ üìÅ infrastructure/                  # Infraestrutura como C√≥digo (opcional)
‚îÇ   ‚îú‚îÄ‚îÄ terraform/                     # Configura√ß√µes Terraform
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.tf                   # Infraestrutura principal
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ snowflake.tf              # Recursos Snowflake
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ variables.tf              # Vari√°veis
‚îÇ   ‚îî‚îÄ‚îÄ scripts/                       # Scripts de setup
‚îÇ       ‚îú‚îÄ‚îÄ setup_snowflake.sql       # Inicializa√ß√£o Snowflake
‚îÇ       ‚îî‚îÄ‚îÄ create_buckets.sh         # Cria√ß√£o de buckets MinIO
‚îÇ
‚îú‚îÄ‚îÄ üìÅ tests/                           # Testes da aplica√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ unit/                          # Testes unit√°rios
‚îÇ   ‚îú‚îÄ‚îÄ integration/                   # Testes de integra√ß√£o
‚îÇ   ‚îî‚îÄ‚îÄ fixtures/                      # Dados de teste
‚îÇ
‚îú‚îÄ‚îÄ üìÅ docs/                            # Documenta√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ ARCHITECTURE.md                # Documenta√ß√£o detalhada da arquitetura
‚îÇ   ‚îú‚îÄ‚îÄ DATA_MODEL.md                  # Documenta√ß√£o do modelo de dados
‚îÇ   ‚îú‚îÄ‚îÄ SETUP.md                       # Guia de setup
‚îÇ   ‚îú‚îÄ‚îÄ TROUBLESHOOTING.md             # Problemas comuns
‚îÇ   ‚îî‚îÄ‚îÄ images/                        # Diagramas de arquitetura
‚îÇ
‚îú‚îÄ‚îÄ .env.example                        # Exemplo de vari√°veis de ambiente
‚îú‚îÄ‚îÄ .gitignore                          # Padr√µes de ignore do Git
‚îú‚îÄ‚îÄ docker-compose.yml                  # Arquivo principal de orquestra√ß√£o
‚îú‚îÄ‚îÄ Makefile                            # Comandos de conveni√™ncia
‚îú‚îÄ‚îÄ requirements.txt                    # Depend√™ncias Python raiz
‚îú‚îÄ‚îÄ README.md                           # Este arquivo
‚îî‚îÄ‚îÄ LICENSE                             # Licen√ßa do projeto
```

---

## üîß Pr√©-requisitos

### Software Necess√°rio

- **Docker Desktop** (4.20+) - [Download](https://www.docker.com/products/docker-desktop)
- **Docker Compose** (2.20+) - Inclu√≠do no Docker Desktop
- **Git** - [Download](https://git-scm.com/downloads)
- **Conta Snowflake** - [Cadastre-se para teste gr√°tis](https://signup.snowflake.com/)
- **Power BI Desktop** (opcional) - [Download](https://powerbi.microsoft.com/)

### Requisitos de Sistema

| Recurso | M√≠nimo | Recomendado |
|----------|---------|-------------|
| **RAM** | 8 GB | 16 GB+ |
| **CPU** | 4 n√∫cleos | 8 n√∫cleos+ |
| **Espa√ßo em Disco** | 20 GB | 50 GB+ |
| **SO** | Windows 10/11, macOS 11+, Linux | Vers√µes mais recentes |

### Requisitos de Rede

- Conex√£o com internet para imagens Docker e Snowflake
- Portas dispon√≠veis: 8080 (Airflow), 9092 (Kafka), 9000-9001 (MinIO), 2181 (Zookeeper)

---

## üöÄ Instala√ß√£o

### 1. Clone o Reposit√≥rio

```bash
git clone https://github.com/maiconaalmeida/spotify-mds-pipeline.git
cd spotify-mds-pipeline
```

### 2. Configure as Vari√°veis de Ambiente

```bash
# Copie o arquivo de exemplo
cp .env.example .env

# Edite o arquivo .env com suas credenciais
nano .env  # ou vim, code, etc.
```

**Vari√°veis Obrigat√≥rias:**

```bash
# Configura√ß√£o Snowflake
SNOWFLAKE_ACCOUNT=seu_identificador_conta
SNOWFLAKE_USER=seu_usuario
SNOWFLAKE_PASSWORD=sua_senha
SNOWFLAKE_WAREHOUSE=COMPUTE_WH
SNOWFLAKE_DATABASE=SPOTIFY_DB
SNOWFLAKE_SCHEMA=BRONZE
SNOWFLAKE_ROLE=ACCOUNTADMIN

# Configura√ß√£o MinIO
MINIO_ROOT_USER=admin
MINIO_ROOT_PASSWORD=senha_admin_minio
MINIO_BUCKET_NAME=spotify-raw-data

# Configura√ß√£o Kafka
KAFKA_BROKER=kafka:9092
KAFKA_TOPIC=spotify_plays

# Configura√ß√£o Airflow
AIRFLOW_UID=50000
AIRFLOW__CORE__FERNET_KEY=sua_chave_fernet_aqui
```

### 3. Inicialize o Snowflake

Execute o script de setup para criar bancos de dados, schemas e tabelas:

```bash
# Conecte ao Snowflake e execute
./infrastructure/scripts/setup_snowflake.sql
```

Ou execute manualmente:

```sql
-- Criar banco de dados e schemas
CREATE DATABASE IF NOT EXISTS SPOTIFY_DB;

CREATE SCHEMA IF NOT EXISTS SPOTIFY_DB.BRONZE;
CREATE SCHEMA IF NOT EXISTS SPOTIFY_DB.SILVER;
CREATE SCHEMA IF NOT EXISTS SPOTIFY_DB.GOLD;

-- Criar tabela da camada Bronze
CREATE TABLE IF NOT EXISTS SPOTIFY_DB.BRONZE.RAW_PLAYS (
    raw_data VARIANT,
    load_timestamp TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),
    source_file STRING,
    _metadata VARIANT
);

-- Criar formato de arquivo para JSON
CREATE FILE FORMAT IF NOT EXISTS SPOTIFY_DB.BRONZE.JSON_FORMAT
    TYPE = 'JSON'
    COMPRESSION = 'AUTO'
    STRIP_OUTER_ARRAY = TRUE;

-- Criar warehouse (se n√£o existir)
CREATE WAREHOUSE IF NOT EXISTS COMPUTE_WH
    WAREHOUSE_SIZE = 'XSMALL'
    AUTO_SUSPEND = 60
    AUTO_RESUME = TRUE;
```

### 4. Construa e Inicie os Servi√ßos

```bash
# Construir todas as imagens Docker
docker-compose build

# Iniciar todos os servi√ßos em modo detached
docker-compose up -d

# Verificar status dos servi√ßos
docker-compose ps
```

**Sa√≠da Esperada:**

```
NOME                    STATUS              PORTAS
kafka                   running             0.0.0.0:9092->9092/tcp
zookeeper               running             0.0.0.0:2181->2181/tcp
minio                   running             0.0.0.0:9000-9001->9000-9001/tcp
airflow-webserver       running             0.0.0.0:8080->8080/tcp
airflow-scheduler       running
producer                running
consumer                running
```

### 5. Acesse os Servi√ßos

| Servi√ßo | URL | Credenciais |
|---------|-----|-------------|
| **Airflow** | http://localhost:8080 | admin / admin |
| **Console MinIO** | http://localhost:9001 | admin / senha_admin_minio |
| **Kafka UI** | http://localhost:9021 | N/A (se Confluent Control Center habilitado) |

### 6. Verifique a Instala√ß√£o

```bash
# Verificar logs do Airflow
docker-compose logs -f airflow-webserver

# Verificar t√≥picos Kafka
docker-compose exec kafka kafka-topics --list --bootstrap-server localhost:9092

# Verificar buckets MinIO
docker-compose exec minio mc ls minio/

# Testar conex√£o Snowflake
docker-compose exec airflow-webserver airflow connections test snowflake_default
```

---

## ‚öôÔ∏è Configura√ß√£o

### Conex√µes do Airflow

Configure a conex√£o Snowflake na UI do Airflow:

1. Navegue at√© **Admin ‚Üí Connections**
2. Clique em **+** para adicionar nova conex√£o
3. Preencha os detalhes:

```
Connection Id: snowflake_default
Connection Type: Snowflake
Account: seu_identificador_conta
Warehouse: COMPUTE_WH
Database: SPOTIFY_DB
Role: ACCOUNTADMIN
Login: seu_usuario
Password: sua_senha
```

### Perfil dbt

Edite `spotify_dbt/profiles.yml`:

```yaml
spotify_dbt:
  outputs:
    dev:
      type: snowflake
      account: "{{ env_var('SNOWFLAKE_ACCOUNT') }}"
      user: "{{ env_var('SNOWFLAKE_USER') }}"
      password: "{{ env_var('SNOWFLAKE_PASSWORD') }}"
      role: ACCOUNTADMIN
      database: SPOTIFY_DB
      warehouse: COMPUTE_WH
      schema: SILVER
      threads: 4
      client_session_keep_alive: False
    
    prod:
      type: snowflake
      account: "{{ env_var('SNOWFLAKE_ACCOUNT') }}"
      user: "{{ env_var('SNOWFLAKE_USER') }}"
      password: "{{ env_var('SNOWFLAKE_PASSWORD') }}"
      role: ACCOUNTADMIN
      database: SPOTIFY_DB
      warehouse: COMPUTE_WH
      schema: GOLD
      threads: 8
      client_session_keep_alive: False
  
  target: dev
```

### Configura√ß√£o de T√≥picos Kafka

Ajuste parti√ß√µes e replica√ß√£o:

```bash
docker-compose exec kafka kafka-topics \
  --create \
  --topic spotify_plays \
  --bootstrap-server localhost:9092 \
  --partitions 3 \
  --replication-factor 1 \
  --config retention.ms=604800000  # 7 dias
```

---

## üéÆ Como Usar

### Iniciando o Pipeline

```bash
# Iniciar todos os servi√ßos
make start

# Ou usando docker-compose
docker-compose up -d
```

### Monitoramento

**Ver Logs:**

```bash
# Todos os servi√ßos
docker-compose logs -f

# Servi√ßo espec√≠fico
docker-compose logs -f producer
docker-compose logs -f consumer
docker-compose logs -f airflow-scheduler
```

**UI do Airflow:**

1. Abra http://localhost:8080
2. Habilite as DAGs: `spotify_ingestion_pipeline` e `spotify_transformation_pipeline`
3. Monitore a execu√ß√£o das tasks na visualiza√ß√£o Graph ou Tree

**Console MinIO:**

1. Abra http://localhost:9001
2. Navegue no bucket `spotify-raw-data`
3. Verifique se arquivos JSON est√£o sendo criados

### Executando dbt Manualmente

```bash
# Entrar no container Airflow
docker-compose exec airflow-webserver bash

# Navegar para o projeto dbt
cd /opt/dbt/spotify_dbt

# Executar todos os modelos
dbt run

# Executar modelos espec√≠ficos
dbt run --models
