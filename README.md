üéß Pipeline de Dados do Spotify com Modern Data Stack
https://img.shields.io/badge/Snowflake-29B5E8?logo=snowflake&logoColor=white
https://img.shields.io/badge/dbt-FF694B?logo=dbt&logoColor=white
https://img.shields.io/badge/Apache%2520Airflow-017CEE?logo=apacheairflow&logoColor=white
https://img.shields.io/badge/Apache%2520Kafka-231F20?logo=apachekafka&logoColor=white
https://img.shields.io/badge/Python-3776AB?logo=python&logoColor=white
https://img.shields.io/badge/Docker-2496ED?logo=docker&logoColor=white
https://img.shields.io/badge/Metabase-509EE3?logo=metabase&logoColor=white

üìñ Sum√°rio
üéØ Motiva√ß√£o do Projeto

üèóÔ∏è Arquitetura do Sistema

üìã Pr√©-requisitos

üöÄ Instala√ß√£o R√°pida

üõ†Ô∏è Configura√ß√£o Detalhada

üîß Como Usar

üìä Metodologia

üîç Solu√ß√£o de Problemas

ü§ù Contribui√ß√£o

üéØ Motiva√ß√£o do Projeto
Este projeto nasceu da necessidade de demonstrar na pr√°tica como construir um pipeline de dados completo em produ√ß√£o usando tecnologias modernas. Muitos tutoriais mostram conceitos isolados, mas poucos integram todas as pe√ßas de um sistema real de dados.

Problemas que este projeto resolve:

Como ingerir dados em tempo real de forma confi√°vel

Como transformar dados brutos em informa√ß√µes valiosas

Como orquestrar processos complexos de dados

Como disponibilizar insights para neg√≥cios de forma acess√≠vel

Como manter um pipeline reproduz√≠vel e versionado

Cen√°rio de Neg√≥cio Simulado:
Imagine que voc√™ √© um engenheiro de dados no Spotify precisando responder perguntas como:

Quais artistas est√£o em tend√™ncia por regi√£o?

Em quais hor√°rios os usu√°rios mais ouvem m√∫sica?

Como o tipo de dispositivo influencia o tempo de escuta?

Quais s√£o os padr√µes de comportamento por estado brasileiro?

üèóÔ∏è Arquitetura do Sistema
Diagrama do Fluxo de Dados
text
[main.py] ‚Üí [Kafka] ‚Üí [MinIO] ‚Üí [Airflow] ‚Üí [Snowflake] ‚Üí [DBT] ‚Üí [Metabase]
   ‚Üë           ‚Üë         ‚Üë         ‚Üë           ‚Üë           ‚Üë         ‚Üë
 Simula√ß√£o   Streaming  Storage  Orquestra√ß√£o  DW         Transforma√ß√£o  Visualiza√ß√£o
Componentes da Arquitetura
Simula√ß√£o de Dados (main.py)

Gera dados realistas de streaming musical

Simula comportamentos de usu√°rios em diferentes regi√µes

Produz dados em tempo real para Kafka

Streaming (Apache Kafka)

Captura eventos de reprodu√ß√£o em tempo real

Garante entrega confi√°vel das mensagens

Permite consumo ass√≠ncrono dos dados

Armazenamento (MinIO)

Armazena dados brutos em formato JSON

Funciona como camada de landing zone

Compat√≠vel com Amazon S3

Orquestra√ß√£o (Apache Airflow)

Agenda e monitora processos de ETL

Gerencia depend√™ncias entre tarefas

Fornece observabilidade do pipeline

Data Warehouse (Snowflake)

Armazena dados nas camadas Bronze, Silver e Gold

Processa consultas complexas com performance

Escalabilidade autom√°tica

Transforma√ß√£o (DBT)

Aplica regras de neg√≥cio aos dados

Cria modelos dimensionais para an√°lise

Garante qualidade dos dados com testes

Visualiza√ß√£o (Metabase)

Dashboard interativo para an√°lise de neg√≥cios

Consultas em tempo real

Self-service analytics

üìã Pr√©-requisitos
Sistema Operacional Compat√≠vel
SO	Vers√£o	Status	Observa√ß√µes
Windows	10/11	‚úÖ Compat√≠vel	Usar WSL2 recomendado
Linux	Ubuntu 18.04+	‚úÖ Totalmente compat√≠vel	Ambiente nativo
macOS	10.15+	‚úÖ Compat√≠vel	Intel e Apple Silicon
Requisitos de Hardware
RAM: M√≠nimo 8GB (16GB recomendado)

CPU: 4 cores ou mais

Armazenamento: 10GB livres

Docker: 4GB de RAM alocada

Software Necess√°rio
Docker Desktop (Download)

Vers√£o 20.10+

Docker Compose inclu√≠do

Python 3.8 ou superior (Download)

Pip para gerenciamento de pacotes

Git (Download)

Conta Snowflake (Free Trial)

Account URL: https://[account].snowflakecomputing.com

üöÄ Instala√ß√£o R√°pida
1. Clonar o Projeto
bash
# Clonar o reposit√≥rio
git clone https://github.com/seu-usuario/spotify-mds-pipeline.git

# Acessar o diret√≥rio
cd spotify-mds-pipeline

# Verificar estrutura do projeto
ls -la
2. Configura√ß√£o Inicial
bash
# Copiar arquivos de configura√ß√£o
cp docker/.env.example docker/.env
cp simulator/.env.example simulator/.env

# Instalar depend√™ncias Python
pip install -r requirements.txt
3. Execu√ß√£o do Pipeline
bash
# Terminal 1: Infraestrutura
docker-compose up -d

# Aguardar 2 minutos para servi√ßos estabilizarem
sleep 120

# Terminal 2: Verifica√ß√£o do sistema
python check_system.py

# Terminal 3: Simulador de dados
python main.py
üõ†Ô∏è Configura√ß√£o Detalhada
Configura√ß√£o do Snowflake
Edite o arquivo docker/.env:

env
# Configura√ß√µes Snowflake
SNOWFLAKE_ACCOUNT=seu_account
SNOWFLAKE_USER=seu_usuario
SNOWFLAKE_PASSWORD=sua_senha
SNOWFLAKE_WAREHOUSE=COMPUTE_WH
SNOWFLAKE_DATABASE=SPOTIFY_ANALYTICS
SNOWFLAKE_SCHEMA=PUBLIC

# Configura√ß√µes Kafka
KAFKA_BOOTSTRAP_SERVERS=kafka:9092
KAFKA_TOPIC=spotify-plays

# Configura√ß√µes MinIO
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
MINIO_BUCKET=spotify-data
Estrutura de Camadas de Dados
Bronze Layer (Raw)

Dados brutos do MinIO

Preserva√ß√£o do formato original

Timestamp de ingest√£o

Silver Layer (Cleaned)

Dados limpos e padronizados

Relacionamentos b√°sicos

Qualidade validada

Gold Layer (Business)

M√©tricas de neg√≥cio

Agrega√ß√µes otimizadas

Modelos dimensionais

üîß Como Usar
Comandos Essenciais
Inicializa√ß√£o Completa
bash
# Script de inicializa√ß√£o autom√°tica (criar arquivo start_pipeline.sh)
#!/bin/bash
echo "üéµ Iniciando Pipeline Spotify MDS..."

echo "1. Levantando infraestrutura Docker..."
docker-compose up -d

echo "2. Aguardando servi√ßos inicializarem..."
sleep 60

echo "3. Verificando sa√∫de do sistema..."
python check_system.py

echo "4. Iniciando simulador de dados..."
python main.py --continuous --rate 5

echo "‚úÖ Pipeline em execu√ß√£o!"
echo "üìä Metabase: http://localhost:3000"
echo "üîÑ Airflow:  http://localhost:8080"
Verifica√ß√£o do Sistema
bash
# Verifica√ß√£o completa
python check_system.py

# Verifica√ß√£o espec√≠fica
python check_system.py --check kafka
python check_system.py --check snowflake
python check_system.py --check minio
Simulador de Dados
bash
# Modo cont√≠nuo (recomendado)
python main.py --continuous --rate 10

# Modo com dura√ß√£o espec√≠fica
python main.py --duration 3600 --rate 5

# Modo debug com logs detalhados
python main.py --continuous --rate 2 --verbose

# Gerar dados para regi√£o espec√≠fica
python main.py --region "southeast" --continuous
Acessando as Interfaces
Metabase (BI Dashboard)
bash
# URL: http://localhost:3000
# Login inicial: admin@example.com / admin

# Configurar conex√£o com Snowflake:
# - Database type: Snowflake
# - Server: sua-conta.snowflakecomputing.com
# - Database: SPOTIFY_ANALYTICS
# - Schema: GOLD
Apache Airflow (Orquestra√ß√£o)
bash
# URL: http://localhost:8080
# Login: airflow / airflow

# DAGs dispon√≠veis:
# - minio_to_snowflake (carga Bronze)
# - snowflake_transform (Silver/Gold)
# - data_quality_checks (valida√ß√µes)
MinIO (Armazenamento)
bash
# URL: http://localhost:9001
# Login: minioadmin / minioadmin

# Verificar dados brutos
# Navegar at√© bucket 'spotify-data'
Monitoramento do Pipeline
bash
# Ver logs em tempo real
docker-compose logs -f

# Ver m√©tricas espec√≠ficas
docker stats

# Ver dados fluindo no Kafka
docker exec -it kafka kafka-console-consumer \
  --topic spotify-plays \
  --bootstrap-server localhost:9092 \
  --from-beginning

# Verificar sa√∫de dos servi√ßos
curl http://localhost:8080/health # Airflow
curl http://localhost:3000/api/health # Metabase
üìä Metodologia
Princ√≠pios de Engenharia de Dados Aplicados
1. Medallion Architecture
Implementamos as tr√™s camadas cl√°ssicas:

Bronze: Dados brutos, imut√°veis

Silver: Dados limpos, confi√°veis

Gold: Dados de neg√≥cio, otimizados

2. Data Contracts

Schema validation no Kafka

Testes de qualidade no DBT

Monitoramento cont√≠nuo no Airflow

3. Infrastructure as Code

Docker Compose para orquestra√ß√£o

DBT para transforma√ß√µes declarativas

Configura√ß√µes versionadas no Git

4. Observability

Logs centralizados

M√©tricas de performance

Alertas de qualidade

Metodologia de Desenvolvimento
Itera√ß√£o 1: Foundation

Setup da infraestrutura Docker

Configura√ß√£o dos servi√ßos b√°sicos

Pipeline de dados simples

Itera√ß√£o 2: Data Quality

Implementa√ß√£o de testes DBT

Valida√ß√µes de schema

Monitoramento de qualidade

Itera√ß√£o 3: Business Intelligence

Dashboards no Metabase

M√©tricas de neg√≥cio

Visualiza√ß√µes interativas

M√©tricas de Sucesso
T√©cnicas:

‚úÖ Lat√™ncia end-to-end < 5 minutos

‚úÖ Disponibilidade > 99% dos servi√ßos

‚úÖ Dados consistentes entre camadas

Neg√≥cio:

‚úÖ Dashboards atualizados em tempo real

‚úÖ Consultas respondidas em < 10 segundos

‚úÖ Interface intuitiva para usu√°rios finais

üîç Solu√ß√£o de Problemas
Problemas Comuns
1. Docker Compose Falha ao Iniciar
bash
# Verificar se portas est√£o livres
netstat -tulpn | grep :3000  # Metabase
netstat -tulpn | grep :8080  # Airflow
netstat -tulpn | grep :9092  # Kafka

# Limpar containers anteriores
docker-compose down
docker system prune -f
2. Erros de Conex√£o com Snowflake
bash
# Verificar credenciais
python -c "
import snowflake.connector
ctx = snowflake.connector.connect(
    user='SEU_USUARIO',
    password='SUA_SENHA', 
    account='SEU_ACCOUNT'
)
print('‚úÖ Conex√£o OK')
"

# Testar conex√£o via DBT
cd spotify_dbt
dbt debug
3. Kafka N√£o Produz/Consome Dados
bash
# Verificar t√≥picos
docker exec -it kafka kafka-topics --list --bootstrap-server localhost:9092

# Testar produ√ß√£o manual
docker exec -it kafka kafka-console-producer \
  --topic test-topic \
  --bootstrap-server localhost:9092

# Ver consumidores
docker exec -it kafka kafka-consumer-groups --list --bootstrap-server localhost:9092
4. Dados N√£o Aparecem no Metabase
bash
# Verificar processamento no Airflow
# 1. Acessar http://localhost:8080
# 2. Verificar DAG 'minio_to_snowflake'
# 3. Checar logs das tasks

# Verificar dados no Snowflake
python check_system.py --check snowflake-data
Scripts de Diagn√≥stico
bash
# Health check completo
./scripts/health_check.sh

# Verificar espa√ßo em disco
docker system df

# Verificar logs de erro
grep -i "error" pipeline_orchestrator.log

# Teste de performance
python benchmarks/pipeline_benchmark.py
üìà Pr√≥ximos Passos e Melhorias
Melhorias Planejadas
Adicionar Apache Spark para processamento batch

Implementar CDC para dados mestres

Adicionar machine learning para recomenda√ß√µes

Implementar data lineage completo

Adicionar monitoramento com Prometheus/Grafana

Expans√µes Poss√≠veis
M√∫ltiplas fontes de dados (YouTube Music, Deezer)

An√°lise de sentimentos de letras

Recomenda√ß√µes em tempo real

Previs√£o de trends musicais

ü§ù Contribui√ß√£o
Como Contribuir
Fork o projeto

Crie uma branch para sua feature

Commit suas mudan√ßas

Push para a branch

Abra um Pull Request

Padr√µes de Desenvolvimento
Siga o estilo de c√≥digo PEP 8 para Python

Use commits sem√¢nticos

Mantenha documenta√ß√£o atualizada

Adicione testes para novas funcionalidades

Ambiente de Desenvolvimento
bash
# Setup do ambiente de dev
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate  # Windows

pip install -r requirements-dev.txt
pre-commit install
üìû Suporte e Contato
Documenta√ß√£o Adicional:

Documenta√ß√£o do Airflow

Documenta√ß√£o do DBT

Documenta√ß√£o do Snowflake

Canais de Ajuda:

üìã Issues do GitHub

üí¨ Discussions

üìß Email

Autor: Maicon Almeida
LinkedIn: aparecidoaalmeida
GitHub: maiconaalmeida

‚≠ê Se este projeto foi √∫til, considere dar uma estrela no reposit√≥rio!

√öltima atualiza√ß√£o: Novembro de 2025